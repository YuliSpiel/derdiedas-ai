{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc2d9f3",
   "metadata": {},
   "source": [
    "- CEFR(유럽 언어 공통 기준, Common European Framework of Reference for Languages) 기반 \n",
    "- 사용자 어학수준 평가 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f4d03",
   "metadata": {},
   "source": [
    "## 학습 데이터 로드\n",
    "- 실제 해당 레벨의 학습자가 어떤 문장을 구사하는지 정리된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03483f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프로젝트 캐시 활성화: /Users/yuli/Documents/AI_Workspace/derdiedas-ai.ai/notebooks/models_cache\n",
      "모델 저장 위치: ./models_cache\n",
      "환경 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 환경 설정 및 경고 비활성화\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 프로젝트 캐시 설정\n",
    "project_cache = \"./models_cache\"\n",
    "os.environ[\"HF_HOME\"] = project_cache\n",
    "print(f\"프로젝트 캐시 활성화: {os.path.abspath(project_cache)}\")\n",
    "\n",
    "# Tokenizers 병렬 처리 경고 비활성화\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# 캐시 디렉토리 확인\n",
    "cache_dir = os.environ.get(\"HF_HOME\", os.path.expanduser(\"~/.cache/huggingface\"))\n",
    "print(f\"모델 저장 위치: {cache_dir}\")\n",
    "\n",
    "print(\"환경 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4588c55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'lang', 'source_name', 'format', 'category', 'cefr_level', 'license', 'text'],\n",
      "    num_rows: 1033\n",
      "})\n",
      "{'title': '1023_0001416.txt', 'lang': 'de', 'source_name': 'merlin-de', 'format': 'paragraph-level', 'category': 'learner', 'cefr_level': 'B2', 'license': 'CC BY-SA 4.0', 'text': 'M. Meier\\nMüllergasse 1\\n12345 Stadt X\\nInternationale Au-pair Vermittlung\\nBahnhofstr. 101\\n65185 Wiesbaden\\n                                   Stadt X, den 14.05.11.\\nSehr geehrte Damen und Herren,\\nihre Anzeige in der Zeitung hat mich sehr erfreut, so was habe ich schon lange gesucht. \\nDa mir die Arbeit mit anderen Menschen sehr großen Spas bereitet, habe ich mich entschlossen, mich zu bewerben.\\nIch bin flexibel und für neuen Aufgaben ofen.\\nTakt, Geduld, warmherzigkeit und Zuverlässigkeit bringe ich mit, sowie Erfahrung im Umgang mit Kindern und der Haushaltsführung.\\nIch spreche Russisch, Englisch, Kasachisch, habe Grundkenntnisse in Deutsch. Zusätzlich habe ich Computerkenntnisse.\\nNaturlich würde ich gern Deutsche Sprache und das Leben in Deutschland kennenlernen. Ich wäre Ihnen sehr dankbar, wenn Sie mir weitere Informationen über Reche, Pflichen und Aufenthaltsformalitäten zuschicken könnten.\\nWerde ich versichert? Welche Freizeitaktivitäten finden statt? Wiviel Stunden in der Woche müssen die Kinder betreut werden? Ob ich was verdiene?\\nÜber eine baldige Antwort würde ich mich sehr freuen\\nMit freundlichen Grüssen\\nMaria Meier'}\n",
      "\n",
      "=== UniversalCEFR 데이터셋 정보 ===\n",
      "총 샘플 수: 1,033개\n",
      "컬럼: ['title', 'lang', 'source_name', 'format', 'category', 'cefr_level', 'license', 'text']\n",
      "\n",
      "첫 번째 샘플:\n",
      "  제목: 1023_0001416.txt\n",
      "  언어: de\n",
      "  카테고리: learner\n",
      "  레벨: B2\n",
      "  텍스트: M. Meier\n",
      "Müllergasse 1\n",
      "12345 Stadt X\n",
      "Internationale Au-pair Vermittlung\n",
      "Bahnhofstr. 101\n",
      "65185 Wiesbaden\n",
      "                                   Stadt X, den 14.05.11.\n",
      "Sehr geehrte Damen und Herren,\n",
      "ihre Anzeige in der Zeitung hat mich sehr erfreut, so was habe ich schon lange gesucht. \n",
      "Da mir die Arbeit mit anderen Menschen sehr großen Spas bereitet, habe ich mich entschlossen, mich zu bewerben.\n",
      "Ich bin flexibel und für neuen Aufgaben ofen.\n",
      "Takt, Geduld, warmherzigkeit und Zuverlässigkeit bringe ich mit, sowie Erfahrung im Umgang mit Kindern und der Haushaltsführung.\n",
      "Ich spreche Russisch, Englisch, Kasachisch, habe Grundkenntnisse in Deutsch. Zusätzlich habe ich Computerkenntnisse.\n",
      "Naturlich würde ich gern Deutsche Sprache und das Leben in Deutschland kennenlernen. Ich wäre Ihnen sehr dankbar, wenn Sie mir weitere Informationen über Reche, Pflichen und Aufenthaltsformalitäten zuschicken könnten.\n",
      "Werde ich versichert? Welche Freizeitaktivitäten finden statt? Wiviel Stunden in der Woche müssen die Kinder betreut werden? Ob ich was verdiene?\n",
      "Über eine baldige Antwort würde ich mich sehr freuen\n",
      "Mit freundlichen Grüssen\n",
      "Maria Meier\n",
      "\n",
      "데이터셋 메타정보 확인 완료\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"UniversalCEFR/merlin_de\", split=\"train\")\n",
    "print(ds)\n",
    "print(ds[0])\n",
    "\n",
    "print(f\"\\n=== UniversalCEFR 데이터셋 정보 ===\")\n",
    "print(f\"총 샘플 수: {len(ds):,}개\")\n",
    "print(f\"컬럼: {ds.column_names}\")\n",
    "print(f\"\\n첫 번째 샘플:\")\n",
    "print(f\"  제목: {ds[0]['title']}\")\n",
    "print(f\"  언어: {ds[0]['lang']}\")\n",
    "print(f\"  카테고리: {ds[0]['category']}\")\n",
    "print(f\"  레벨: {ds[0]['cefr_level']}\")\n",
    "print(f\"  텍스트: {ds[0]['text']}\")\n",
    "\n",
    "print(\"\\n데이터셋 메타정보 확인 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69629e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysbd\n",
    "seg = pysbd.Segmenter(language=\"de\", clean=True)\n",
    "def split_sentences(text: str):\n",
    "    sents = seg.segment(text)\n",
    "    # 길이 필터 등 후처리\n",
    "    return [s.strip() for s in sents if 5 <= len(s.split()) <= 80]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1c8d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 생성 (2~3문장)\n",
    "def make_windows(sents, win=2, stride=1):\n",
    "    out = []\n",
    "    for i in range(0, len(sents) - win + 1, stride):\n",
    "        out.append(\" \".join(sents[i : i + win]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ded7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_instances_windows_only(\n",
    "    doc_id: str,\n",
    "    text: str,\n",
    "    doc_label: str,\n",
    "    split_sentences,\n",
    "    make_windows,\n",
    "    wins=(2, 3),\n",
    "    stride=1,\n",
    "    min_tokens=5,\n",
    "    max_tokens=120,\n",
    "    add_numeric_level=True\n",
    "):\n",
    "    \"\"\"\n",
    "    문장은 저장하지 않고, 2~3문장 윈도우만 생성하여 반환.\n",
    "    - doc_label은 window 레벨에도 그대로 전파 (label_doc 유지)\n",
    "    - add_numeric_level=True면 레벨을 수치화한 label_num도 추가 (예: A1=1, A1+=1.5, A2=2, ...)\n",
    "    \"\"\"\n",
    "    def _tok_len(t: str) -> int:\n",
    "        return len(t.split())\n",
    "\n",
    "    # CEFR 레벨 수치화(선택)\n",
    "    level2num = {\n",
    "        \"A1\":1.0, \"A1+\":1.5,\n",
    "        \"A2\":2.0, \"A2+\":2.5,\n",
    "        \"B1\":3.0, \"B1+\":3.5,\n",
    "        \"B2\":4.0, \"B2+\":4.5,\n",
    "        \"C1\":5.0, \"C2\":6.0\n",
    "    }\n",
    "    label_num = level2num.get(doc_label, None) if add_numeric_level else None\n",
    "\n",
    "    instances = []\n",
    "    sents = split_sentences(text)\n",
    "\n",
    "    for w in wins:\n",
    "        wins_out = make_windows(sents, win=w, stride=stride)\n",
    "        for j, item in enumerate(wins_out):\n",
    "            # make_windows가 (span_idxs, text) 또는 text 만 반환하는 두 케이스 모두 지원\n",
    "            if isinstance(item, tuple) and len(item) == 2:\n",
    "                span, wtext = item\n",
    "            else:\n",
    "                span, wtext = None, item\n",
    "            if min_tokens <= _tok_len(wtext) <= max_tokens:\n",
    "                row = {\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"unit\": f\"win{w}\",\n",
    "                    \"idx\": j,\n",
    "                    \"text\": wtext,\n",
    "                    \"label_doc\": doc_label,     # 문서 라벨 유지\n",
    "                    \"span\": span                # 원 문장 인덱스 범위 (있을 경우)\n",
    "                }\n",
    "                if label_num is not None:\n",
    "                    row[\"label_num\"] = label_num\n",
    "                instances.append(row)\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6214e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 네 구현체 import (split_sentences, make_windows)\n",
    "# from your_module import split_sentences, make_windows\n",
    "\n",
    "def process_to_windows_only(\n",
    "    ds_iter,\n",
    "    text_key: str = \"text\",\n",
    "    label_key: str = \"cefr_level\",\n",
    "    id_key: str | None = None,\n",
    "    max_docs: int | None = None,\n",
    "    **doc_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    HF dataset iterable을 받아 윈도우 인스턴스만 DataFrame으로 변환\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for k, rec in enumerate(ds_iter):\n",
    "        if max_docs is not None and k >= max_docs:\n",
    "            break\n",
    "        doc_id = rec[id_key] if id_key and id_key in rec else f\"doc_{k}\"\n",
    "        text = rec[text_key]\n",
    "        label = rec[label_key]\n",
    "        rows = doc_to_instances_windows_only(\n",
    "            doc_id=doc_id,\n",
    "            text=text,\n",
    "            doc_label=label,\n",
    "            split_sentences=split_sentences,\n",
    "            make_windows=make_windows,\n",
    "            **doc_kwargs\n",
    "        )\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if not df.empty and {\"doc_id\",\"unit\",\"idx\"}.issubset(df.columns):\n",
    "        df = df.sort_values([\"doc_id\",\"unit\",\"idx\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def save_parquet_jsonl(df: pd.DataFrame, base_path: str):\n",
    "    os.makedirs(os.path.dirname(base_path), exist_ok=True)\n",
    "    pq = base_path + \".parquet\"\n",
    "    jl = base_path + \".jsonl\"\n",
    "    df.to_parquet(pq, index=False)\n",
    "    with open(jl, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in df.to_dict(orient=\"records\"):\n",
    "            import json\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"✅ Saved: {pq} | rows={len(df):,}\")\n",
    "    print(f\"✅ Saved: {jl} | rows={len(df):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c455dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def verify_windows_df(df: pd.DataFrame, preview=8):\n",
    "    assert set(df[\"unit\"].unique()) <= {\"win2\",\"win3\"}, \"⚠️ sent 행이 섞여 있습니다. (unit 컬럼 확인)\"\n",
    "\n",
    "    print(\"🧾 Preview\")\n",
    "    print(df[[\"doc_id\",\"unit\",\"idx\",\"label_doc\",\"text\"]].head(preview))\n",
    "\n",
    "    print(\"\\n📊 Unit counts\")\n",
    "    print(df[\"unit\"].value_counts())\n",
    "\n",
    "    # 길이 통계\n",
    "    lens = df[\"text\"].str.split().apply(len)\n",
    "    print(\"\\n📈 Token length stats\")\n",
    "    print(f\"- mean: {lens.mean():.1f}, min: {lens.min()}, max: {lens.max()}\")\n",
    "\n",
    "    # 라벨 분포\n",
    "    print(\"\\n🏷️ Label distribution (label_doc)\")\n",
    "    print(df[\"label_doc\"].value_counts())\n",
    "\n",
    "    # 문서별 커버리지 샘플\n",
    "    sample_doc = df[\"doc_id\"].iloc[0]\n",
    "    print(f\"\\n👀 Sample windows for doc_id={sample_doc}\")\n",
    "    print(df[df[\"doc_id\"] == sample_doc].head(10)[[\"unit\",\"idx\",\"text\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cac1d2",
   "metadata": {},
   "source": [
    "## 분할된 데이터 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4460a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: outputs/parsed/ucefr_elg_en_windows_only.parquet | rows=5,996\n",
      "✅ Saved: outputs/parsed/ucefr_elg_en_windows_only.jsonl | rows=5,996\n",
      "🧾 Preview\n",
      "  doc_id  unit  idx label_doc  \\\n",
      "0  doc_0  win2    0        B2   \n",
      "1  doc_0  win2    1        B2   \n",
      "2  doc_0  win2    2        B2   \n",
      "3  doc_0  win3    0        B2   \n",
      "4  doc_0  win3    1        B2   \n",
      "5  doc_0  win3    2        B2   \n",
      "6  doc_1  win2    0        B2   \n",
      "7  doc_1  win2    1        B2   \n",
      "8  doc_1  win2    2        B2   \n",
      "9  doc_1  win2    3        B2   \n",
      "\n",
      "                                                text  \n",
      "0  Sehr geehrte Damen und Herren, ihre Anzeige in...  \n",
      "1  Ich bin flexibel und für neuen Aufgaben ofen. ...  \n",
      "2  Naturlich würde ich gern Deutsche Sprache und ...  \n",
      "3  Sehr geehrte Damen und Herren, ihre Anzeige in...  \n",
      "4  Ich bin flexibel und für neuen Aufgaben ofen. ...  \n",
      "5  Naturlich würde ich gern Deutsche Sprache und ...  \n",
      "6  Sehr geehrte Damen und Herren ich habe Ihre An...  \n",
      "7  Für diese Stelle bringe ich alle Voraussetzung...  \n",
      "8  Diese Erfarung wurde mich späte gut helfen, be...  \n",
      "9  Kann ich mit meinem Armenischen Pass nach Deut...  \n",
      "\n",
      "📊 Unit counts\n",
      "unit\n",
      "win2    3163\n",
      "win3    2833\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📈 Token length stats\n",
      "- mean: 29.1, min: 10, max: 115\n",
      "\n",
      "🏷️ Label distribution (label_doc)\n",
      "label_doc\n",
      "B2    2579\n",
      "B1    1990\n",
      "A2     933\n",
      "C1     372\n",
      "A1      86\n",
      "C2      36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "👀 Sample windows for doc_id=doc_0\n",
      "   unit  idx                                               text\n",
      "0  win2    0  Sehr geehrte Damen und Herren, ihre Anzeige in...\n",
      "1  win2    1  Ich bin flexibel und für neuen Aufgaben ofen. ...\n",
      "2  win2    2  Naturlich würde ich gern Deutsche Sprache und ...\n",
      "3  win3    0  Sehr geehrte Damen und Herren, ihre Anzeige in...\n",
      "4  win3    1  Ich bin flexibel und für neuen Aufgaben ofen. ...\n",
      "5  win3    2  Naturlich würde ich gern Deutsche Sprache und ...\n"
     ]
    }
   ],
   "source": [
    "# 1) 데이터 로드\n",
    "ds = load_dataset(\"UniversalCEFR/merlin_de\", split=\"train\")\n",
    "\n",
    "# 2) 윈도우 인스턴스 생성 (문장 저장 X)\n",
    "df_win = process_to_windows_only(\n",
    "    ds_iter=ds,\n",
    "    text_key=\"text\",\n",
    "    label_key=\"cefr_level\",\n",
    "    id_key=None,          # 데이터에 고유 id 있으면 지정\n",
    "    max_docs=None,        # 일부만 테스트하려면 숫자\n",
    "    wins=(2,3),           # 2~3문장 윈도우\n",
    "    stride=3,         # 중복 설정\n",
    "    min_tokens=5,\n",
    "    max_tokens=120,\n",
    "    add_numeric_level=True\n",
    ")\n",
    "\n",
    "# 3) 저장\n",
    "base = \"outputs/parsed/ucefr_elg_en_windows_only\"\n",
    "save_parquet_jsonl(df_win, base)\n",
    "\n",
    "# 4) 검증\n",
    "verify_windows_df(df_win, preview=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ea0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_win"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
