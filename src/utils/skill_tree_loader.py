"""
ìŠ¤í‚¬ íŠ¸ë¦¬ CSVë¥¼ ì˜¨í†¨ë¡œì§€ êµ¬ì¡°ë¡œ ë³€í™˜í•˜ëŠ” ìœ í‹¸ë¦¬í‹°

skill_tree.csv íŒŒì¼ì„ ì½ì–´ì„œ GrammarTopic êµ¬ì¡°ë¡œ ë§¤í•‘
"""

import csv
from pathlib import Path
from typing import Dict, List
import json


class SkillTreeLoader:
    """ìŠ¤í‚¬ íŠ¸ë¦¬ CSV ë¡œë”"""

    def __init__(self, csv_path: str = None):
        if csv_path is None:
            project_root = Path(__file__).parent.parent.parent
            csv_path = project_root / "data" / "grammar_ontology" / "skill_tree.csv"

        self.csv_path = Path(csv_path)
        self.skills: List[Dict] = []

    def load(self) -> List[Dict]:
        """CSV ë¡œë“œ"""
        with open(self.csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            self.skills = list(reader)

        print(f"âœ… {len(self.skills)}ê°œ ìŠ¤í‚¬ ë¡œë“œ ì™„ë£Œ")
        return self.skills

    def to_ontology_structure(self) -> Dict:
        """ì˜¨í†¨ë¡œì§€ JSON êµ¬ì¡°ë¡œ ë³€í™˜"""
        topics = []

        for skill in self.skills:
            # prerequisites íŒŒì‹± (ì„¸ë¯¸ì½œë¡  ë˜ëŠ” ì‰¼í‘œ êµ¬ë¶„)
            prereq_str = skill.get('prerequisites', '').strip()
            if prereq_str:
                prerequisites = [p.strip() for p in prereq_str.replace(';', ',').split(',') if p.strip()]
            else:
                prerequisites = []

            # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (area í•„ë“œì—ì„œ)
            area = skill.get('area', 'Grammar')
            category = self._map_area_to_category(area)

            topic = {
                "id": skill['skill_id'],
                "title_de": skill['name'].split('â€“')[0].strip() if 'â€“' in skill['name'] else skill['name'],
                "title_ko": skill['hint'],
                "title_en": skill['name'],

                "cefr_level": skill['cefr'],
                "category": category,
                "subcategory": area,
                "tags": self._extract_tags(skill),

                "difficulty_score": self._calculate_difficulty(skill['cefr']),
                "estimated_time": 15,  # ê¸°ë³¸ê°’
                "prerequisites": prerequisites,
                "related_topics": [],  # GPTê°€ ì±„ìš¸ ì˜ˆì •

                "summary": f"{skill['name']} - {skill['hint']}",
                "rules": [],  # GPTê°€ ì±„ìš¸ ì˜ˆì •
                "examples": [],  # GPTê°€ ì±„ìš¸ ì˜ˆì •
                "exercises": [],  # GPTê°€ ì±„ìš¸ ì˜ˆì •
                "common_mistakes": [],  # GPTê°€ ì±„ìš¸ ì˜ˆì •

                "source": "Skill Tree CSV",
                "created_at": "",
                "updated_at": "",

                # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
                "ud_features": skill.get('ud_features', '')
            }

            topics.append(topic)

        ontology = {
            "version": "1.0",
            "created_at": "",
            "metadata": {
                "total_topics": len(topics),
                "by_category": self._count_by_field(topics, 'category'),
                "by_cefr_level": self._count_by_field(topics, 'cefr_level'),
            },
            "topics": topics
        }

        return ontology

    def _map_area_to_category(self, area: str) -> str:
        """Areaë¥¼ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        mapping = {
            'Articles': 'articles',
            'Nouns': 'nouns',
            'Nouns & Case': 'cases',
            'Pronouns': 'pronouns',
            'Adjectives': 'adjectives',
            'Verbs': 'verbs',
            'Negation': 'negation',
            'Word Order': 'word_order',
            'Clauses': 'clauses',
            'Questions': 'questions',
            'Imperatives': 'imperatives',
            'Prepositions': 'prepositions',
            'Numerals&Time': 'time',
            'Particles': 'particles'
        }
        return mapping.get(area, 'other')

    def _extract_tags(self, skill: Dict) -> List[str]:
        """ìŠ¤í‚¬ì—ì„œ íƒœê·¸ ì¶”ì¶œ"""
        tags = []

        # nameì—ì„œ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ
        name = skill['name']
        if 'â€“' in name:
            parts = [p.strip() for p in name.split('â€“')]
            tags.extend(parts)

        # hint ì¶”ê°€
        if skill['hint']:
            tags.append(skill['hint'])

        return tags[:5]

    def _calculate_difficulty(self, cefr: str) -> float:
        """CEFR ë ˆë²¨ë¡œ ë‚œì´ë„ ê³„ì‚°"""
        scores = {
            'A1': 1.0,
            'A2': 2.0,
            'B1': 3.0,
            'B2': 4.0,
            'C1': 5.0
        }
        return scores.get(cefr, 2.5)

    def _count_by_field(self, topics: List[Dict], field: str) -> Dict:
        """í•„ë“œë³„ ì¹´ìš´íŠ¸"""
        counts = {}
        for topic in topics:
            value = topic[field]
            counts[value] = counts.get(value, 0) + 1
        return counts

    def save_ontology_template(self, output_path: str = None):
        """ì˜¨í†¨ë¡œì§€ í…œí”Œë¦¿ ì €ìž¥"""
        if output_path is None:
            project_root = Path(__file__).parent.parent.parent
            output_path = project_root / "data" / "grammar_ontology" / "ontology_template.json"

        ontology = self.to_ontology_structure()

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(ontology, f, ensure_ascii=False, indent=2)

        print(f"ðŸ’¾ ì˜¨í†¨ë¡œì§€ í…œí”Œë¦¿ ì €ìž¥: {output_path}")
        print(f"   - ì´ {len(ontology['topics'])}ê°œ ì£¼ì œ")
        print(f"   - GPTì—ê²Œ rules, examples, exercises ìƒì„± ìš”ì²­í•˜ì„¸ìš”")

        # í†µê³„ ì¶œë ¥
        print("\nðŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for cat, count in sorted(ontology['metadata']['by_category'].items()):
            print(f"   {cat}: {count}ê°œ")

        print("\nðŸ“Š CEFR ë ˆë²¨ë³„ ë¶„í¬:")
        for level in ['A1', 'A2', 'B1', 'B2', 'C1']:
            count = ontology['metadata']['by_cefr_level'].get(level, 0)
            if count > 0:
                print(f"   {level}: {count}ê°œ")


if __name__ == "__main__":
    loader = SkillTreeLoader()
    skills = loader.load()
    loader.save_ontology_template()
